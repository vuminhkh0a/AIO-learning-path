{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "def pad_sequences(sequences):\n",
    "    if len(sequences) == 0:\n",
    "        return []\n",
    "    max_len = max([len(sub) for sub in sequences])\n",
    "    for sub in sequences:\n",
    "        while len(sub) < max_len:\n",
    "            sub.append(0)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "assert pad_sequences([[1, 2], [3, 4, 5], [6]]) == [[1, 2, 0], [3, 4, 5], [6, 0, 0]], \"Test 1 Failed\"\n",
    "assert pad_sequences([[1, 1], [2, 2], [3, 3]]) == [[1, 1], [2, 2], [3, 3]], \"Test 2 Failed\"\n",
    "assert pad_sequences([[1, 2, 3], []]) == [[1, 2, 3], [0, 0, 0]], \"Test 3 Failed\"\n",
    "assert pad_sequences([[7, 8]]) == [[7, 8]], \"Test 4 Failed\"\n",
    "assert pad_sequences([]) == [], \"Test 5 Failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1e5d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "def split_dataset(data, train_ratio, val_ratio):\n",
    "    num_train = int(len(data) * train_ratio)\n",
    "    num_val = int(len(data) * val_ratio)\n",
    "    num_test = len(data) - num_train - num_val\n",
    "\n",
    "    train_set = data[ : num_train]\n",
    "    val_set = data[num_train : num_val + num_train]\n",
    "    test_set = data[num_val + num_train : num_val + num_train + num_test]\n",
    "\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "# Test 1: Chia tỷ lệ chuẩn\n",
    "dataset = list(range(100))\n",
    "train, val, test = split_dataset(dataset, 0.7, 0.15)\n",
    "assert (len(train), len(val), len(test)) == (70, 15, 15), \"Test 1 Failed\"\n",
    "\n",
    "# Test 2: Dữ liệu nhỏ, chia đều, kiểm tra làm tròn\n",
    "dataset = ['a', 'b', 'c']\n",
    "train, val, test = split_dataset(dataset, 0.5, 0.5)\n",
    "assert (len(train), len(val), len(test)) == (1, 1, 1), \"Test 2 Failed\"\n",
    "\n",
    "# Test 3: Không có tập validation\n",
    "dataset = list(range(5))\n",
    "train, val, test = split_dataset(dataset, 0.8, 0.0)\n",
    "assert (train, val, test) == (list(range(4)), [], [4]), \"Test 3 Failed\"\n",
    "\n",
    "# Test 4: Dữ liệu rỗng\n",
    "dataset = []\n",
    "train, val, test = split_dataset(dataset, 0.6, 0.2)\n",
    "assert (train, val, test) == ([], [], []), \"Test 4 Failed\"\n",
    "\n",
    "# Test 5: Tổng tỉ lệ nhỏ hơn 1, phần còn lại là test\n",
    "dataset = list(range(10))\n",
    "train, val, test = split_dataset(dataset, 0.2, 0.3) # 2, 3, 5\n",
    "assert (train, val, test) == (list(range(2)), list(range(2, 5)), list(range(5, 10))), \"Test 5 Failed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d15af9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "def flatten_tokens(corpus):\n",
    "    if len(corpus) == 0:\n",
    "        return []\n",
    "\n",
    "    return [word for sentence in corpus for word in sentence] \n",
    "\n",
    "# Test 1: Hai câu, mỗi câu có nhiều từ, làm phẳng toàn bộ\n",
    "assert flatten_tokens([[\"hello\", \"world\"], [\"this\", \"is\", \"a\", \"test\"]]) == [\"hello\", \"world\", \"this\", \"is\", \"a\", \"test\"], \"Test 1 Failed\"\n",
    "\n",
    "# Test 2: Một câu ngắn và một câu 1 từ, kiểm tra xử lý danh sách không đều\n",
    "assert flatten_tokens([[\"a\", \"b\"], [\"c\"]]) == [\"a\", \"b\", \"c\"], \"Test 2 Failed\"\n",
    "\n",
    "# Test 3: Kho văn bản rỗng, đầu ra là list rỗng\n",
    "assert flatten_tokens([]) == [], \"Test 3 Failed\"\n",
    "\n",
    "# Test 4: Chỉ có một câu, kiểm tra hoạt động đơn lẻ\n",
    "assert flatten_tokens([[\"single\", \"sentence\"]]) == [\"single\", \"sentence\"], \"Test 4 Failed\"\n",
    "\n",
    "# Test 5: Nhiều câu có độ dài khác nhau, kiểm tra tính ổn định của kết quả\n",
    "assert flatten_tokens([[\"deep\", \"learning\"], [\"rocks\"], [\"NLP\", \"is\", \"fun\"]]) == [\"deep\", \"learning\", \"rocks\", \"NLP\", \"is\", \"fun\"], \"Test 5 Failed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a10585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "def one_hot_encode(labels, classes):\n",
    "    num_labels = len(labels)\n",
    "    num_classes = len(classes)\n",
    "    output = [[0] * num_classes for _ in range(num_labels)] \n",
    "\n",
    "    for i in range(num_labels):\n",
    "        for j in range(num_classes):\n",
    "            if labels[i] == classes[j]:\n",
    "                output[i][j] = 1\n",
    "                \n",
    "    return output\n",
    "\n",
    "# Test 1: Danh sách nhãn đầy đủ, kiểm tra thứ tự và ánh xạ chính xác\n",
    "assert one_hot_encode([\"dog\", \"cat\", \"bird\", \"dog\"], [\"cat\", \"dog\", \"bird\"]) == [[0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0]], \"Test 1 Failed\"\n",
    "\n",
    "# Test 2: Danh sách nhãn rỗng, kết quả cũng phải là danh sách rỗng\n",
    "assert one_hot_encode([], [\"cat\", \"dog\", \"bird\"]) == [], \"Test 2 Failed\"\n",
    "\n",
    "# Test 3: Trường hợp chỉ có hai lớp, lặp lại nhãn nhiều lần\n",
    "assert one_hot_encode([\"A\", \"A\", \"B\"], [\"A\", \"B\"]) == [[1, 0], [1, 0], [0, 1]], \"Test 3 Failed\"\n",
    "\n",
    "\n",
    "# Test 4: Chỉ có một nhãn duy nhất, kiểm tra đầu ra đơn\n",
    "assert one_hot_encode([\"cat\"], [\"cat\", \"dog\", \"bird\"]) == [[1, 0, 0]], \"Test 4 Failed\"\n",
    "\n",
    "# Test 5: Lớp có nhãn dài, kiểm tra ánh xạ không bị ảnh hưởng bởi độ dài chuỗi\n",
    "assert one_hot_encode([\"sad\", \"happy\"], [\"happy\", \"sad\", \"neutral\"]) == [[0, 1, 0], [1, 0, 0]], \"Test 5 Failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "71d175b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "def filter_low_confidence_boxes(predictions, threshold):\n",
    "    return [predict for predict in predictions if predict[1] >= threshold]\n",
    "\n",
    "# Test 1: Có 2 boxes đủ điểm tự tin (>= 0.8), 1 box bị loại\n",
    "predictions1 = [[0, 0.95, 10, 10, 50, 50], [1, 0.4, 20, 20, 30, 30], [0, 0.88, 15, 15, 40, 40]]\n",
    "assert filter_low_confidence_boxes(predictions1, 0.8) == [[0, 0.95, 10, 10, 50, 50], [0, 0.88, 15, 15, 40, 40]], \"Test 1 Failed\"\n",
    "\n",
    "# Test 2: Threshold cao hơn mọi boxes -> kết quả rỗng\n",
    "assert filter_low_confidence_boxes(predictions1, 0.99) == [], \"Test 2 Failed\"\n",
    "\n",
    "# Test 3: Dữ liệu đầu vào rỗng -> đầu ra cũng rỗng\n",
    "assert filter_low_confidence_boxes([], 0.5) == [], \"Test 3 Failed\"\n",
    "\n",
    "# Test 4: Một box có confidence đúng bằng threshold -> vẫn được giữ lại\n",
    "predictions2 = [[0, 0.5, 5, 5, 10, 10]]\n",
    "assert filter_low_confidence_boxes(predictions2, 0.5) == [[0, 0.5, 5, 5, 10, 10]], \"Test 4 Failed\"\n",
    "\n",
    "# Test 5: Tất cả các boxes đều đủ điểm -> không loại boxes nào\n",
    "predictions3 = [[0, 0.85, 1, 2, 3, 4], [1, 0.95, 4, 5, 6, 7]]\n",
    "assert filter_low_confidence_boxes(predictions3, 0.5) == predictions3, \"Test 5 Failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "def min_max_scale(data):\n",
    "    if len(data) == 0:\n",
    "        return []\n",
    "    \n",
    "    min_val = min(data)\n",
    "    max_val = max(data)\n",
    "    \n",
    "    if min_val == max_val:\n",
    "        return [0] * len(data)\n",
    "    \n",
    "    return [(x - min_val) / (max_val - min_val) for x in data]\n",
    "\n",
    "# Test 1: Chuẩn hóa danh sách số nguyên dương\n",
    "assert min_max_scale([10, 20, 50, 30]) == [0.0, 0.25, 1.0, 0.5], \"Test 1 Failed\"\n",
    "\n",
    "# Test 2: Danh sách chứa số âm và số 0\n",
    "assert min_max_scale([-10, 0, 10]) == [0.0, 0.5, 1.0], \"Test 2 Failed\"\n",
    "\n",
    "# Test 3: Tất cả các phần tử giống nhau, tránh chia cho 0\n",
    "assert min_max_scale([5, 5, 5, 5]) == [0.0, 0.0, 0.0, 0.0], \"Test 3 Failed\"\n",
    "\n",
    "# Test 4: Danh sách đầu vào rỗng\n",
    "assert min_max_scale([]) == [], \"Test 4 Failed\"\n",
    "\n",
    "# Test 5: Dữ liệu đã ở trong khoảng [0, 1]\n",
    "# Lưu ý: Do sai số floating point, ta cần so sánh với một sai số nhỏ\n",
    "scaled_data = min_max_scale([0.1, 0.5, 0.9])\n",
    "expected_data = [0.0, 0.5, 1.0]\n",
    "assert all(abs(a - b) < 1e-9 for a, b in zip(scaled_data, expected_data)), \"Test 5 Failed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fca57645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    if len(y_true) == 0:\n",
    "        return 0.0\n",
    "    return float(sum(1 for y, y_hat in zip(y_true, y_pred) if y == y_hat) / len(y_pred))\n",
    "\n",
    "# Test 1: Các nhãn là chuỗi, độ chính xác 80%\n",
    "y_true1 = [\"cat\", \"dog\", \"cat\", \"bird\", \"dog\"]\n",
    "y_pred1 = [\"cat\", \"dog\", \"cat\", \"dog\", \"dog\"]\n",
    "assert calculate_accuracy(y_true1, y_pred1) == 0.8, \"Test 1 Failed\"\n",
    "\n",
    "# Test 2: Các nhãn là số, độ chính xác 100%\n",
    "y_true2 = [1, 0, 1, 1, 0]\n",
    "y_pred2 = [1, 0, 1, 1, 0]\n",
    "assert calculate_accuracy(y_true2, y_pred2) == 1.0, \"Test 2 Failed\"\n",
    "\n",
    "# Test 3: Độ chính xác 0%\n",
    "y_true3 = [0, 0, 0]\n",
    "y_pred3 = [1, 1, 1]\n",
    "assert calculate_accuracy(y_true3, y_pred3) == 0.0, \"Test 3 Failed\"\n",
    "\n",
    "# Test 4: Danh sách rỗng\n",
    "\n",
    "assert calculate_accuracy([], []) == 0.0, \"Test 4 Failed\"\n",
    "\n",
    "# Test 5: Độ chính xác 50%\n",
    "y_true5 = [\"A\", \"B\"]\n",
    "y_pred5 = [\"A\", \"C\"]\n",
    "assert calculate_accuracy(y_true5, y_pred5) == 0.5, \"Test 5 Failed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "59273e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "import random\n",
    "\n",
    "def add_noise_augmentation(time_series, noise_level):\n",
    "    return [x + noise_level for x in time_series]\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "# Test 1: Thêm nhiễu vào một chuỗi thời gian\n",
    "ts1 = [10, 11, 12, 11, 10]\n",
    "augmented_ts1 = add_noise_augmentation(ts1, 0.1)\n",
    "assert len(augmented_ts1) == len(ts1), \"Test 1 Failed: Length mismatch\"\n",
    "\n",
    "assert augmented_ts1 != ts1, \\\n",
    "\"Test 1 Failed: Series should be different after adding noise\"\n",
    "\n",
    "# Test 2: noise_level = 0, chuỗi không thay đổi\n",
    "ts2 = [100, 200, 150]\n",
    "augmented_ts2 = add_noise_augmentation(ts2, 0.0)\n",
    "assert augmented_ts2 == ts2, \\\n",
    "\"Test 2 Failed: Series should be identical with zero noise\"\n",
    "\n",
    "# Test 3: Chuỗi rỗng\n",
    "assert add_noise_augmentation([], 0.5) == [], \\\n",
    "\"Test 3 Failed: Empty list should return empty list\"\n",
    "\n",
    "# Test 4: Kiểm tra xem giá trị có thay đổi không\n",
    "# Vì kết quả là ngẫu nhiên, ta chỉ kiểm tra xem nó có khác bản gốc không\n",
    "ts4 = [5]\n",
    "augmented_ts4 = add_noise_augmentation(ts4, 1.0)\n",
    "assert augmented_ts4 != ts4, \"Test 4 Failed: Single element should change\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb66008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8dcf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "def create_bow_vectors(corpus, vocabulary):\n",
    "    vocab_map = {word: i for i, word in enumerate(vocabulary)}\n",
    "\n",
    "    bow_vectors = []\n",
    "\n",
    "    for document in corpus:\n",
    "        tmp = [0] * len(vocabulary)\n",
    "        for token in document:\n",
    "            if token in vocabulary:\n",
    "                id = vocab_map[token]\n",
    "                tmp[id] += 1\n",
    "        bow_vectors.append(tmp)\n",
    "\n",
    "\n",
    "    return bow_vectors\n",
    "\n",
    "\n",
    "vocab = [\"apple\", \"banana\", \"fruit\", \"orange\"]\n",
    "\n",
    "# Test 1: Hai tài liệu với các từ trong từ điển\n",
    "corpus1 = [[\"apple\", \"banana\", \"apple\"], [\"fruit\", \"orange\"]]\n",
    "expected1 = [[2, 1, 0, 0], [0, 0, 1, 1]]\n",
    "assert create_bow_vectors(corpus1, vocab) == expected1, \"Test 1 Failed\"\n",
    "\n",
    "# Test 2: Tài liệu chứa từ không có trong từ điển\n",
    "corpus2 = [[\"apple\", \"grape\", \"banana\"]] # \"grape\" không có trong vocab\n",
    "expected2 = [[1, 1, 0, 0]]\n",
    "assert create_bow_vectors(corpus2, vocab) == expected2, \"Test 2 Failed\"\n",
    "\n",
    "# Test 3: Một tài liệu rỗng\n",
    "corpus3 = [[]]\n",
    "expected3 = [[0, 0, 0, 0]]\n",
    "assert create_bow_vectors(corpus3, vocab) == expected3, \"Test 3 Failed\"\n",
    "\n",
    "# Test 4: Kho văn bản rỗng\n",
    "assert create_bow_vectors([], vocab) == [], \"Test 4 Failed\"\n",
    "\n",
    "# Test 5: Từ điển lớn hơn, tài liệu chỉ chứa một vài từ\n",
    "vocab5 = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "corpus5 = [[\"a\", \"c\", \"e\", \"a\"]]\n",
    "expected5 = [[2, 0, 1, 0, 1]]\n",
    "assert create_bow_vectors(corpus5, vocab5) == expected5, \"Test 5 Failed\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
